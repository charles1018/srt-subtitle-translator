# API æ–‡æª”

> SRT Subtitle Translator é–‹ç™¼è€… API åƒè€ƒ

## ç›®éŒ„

- [æ¦‚è¿°](#æ¦‚è¿°)
- [æ ¸å¿ƒæ¨¡çµ„ (core)](#æ ¸å¿ƒæ¨¡çµ„-core)
  - [ConfigManager](#configmanager)
  - [CacheManager](#cachemanager)
  - [ModelManager](#modelmanager)
  - [PromptManager](#promptmanager)
- [ç¿»è­¯æ¨¡çµ„ (translation)](#ç¿»è­¯æ¨¡çµ„-translation)
  - [TranslationClient](#translationclient)
  - [TranslationManager](#translationmanager)
- [æª”æ¡ˆè™•ç†æ¨¡çµ„ (file_handling)](#æª”æ¡ˆè™•ç†æ¨¡çµ„-file_handling)
  - [FileHandler](#filehandler)
- [æœå‹™å·¥å»  (services)](#æœå‹™å·¥å» -services)
  - [ServiceFactory](#servicefactory)
- [å·¥å…·æ¨¡çµ„ (utils)](#å·¥å…·æ¨¡çµ„-utils)
  - [éŒ¯èª¤é¡åˆ¥](#éŒ¯èª¤é¡åˆ¥)
  - [è¼”åŠ©å‡½æ•¸](#è¼”åŠ©å‡½æ•¸)
- [ä½¿ç”¨ç¯„ä¾‹](#ä½¿ç”¨ç¯„ä¾‹)
- [æœ€ä½³å¯¦è¸](#æœ€ä½³å¯¦è¸)

---

## æ¦‚è¿°

æœ¬ API æ–‡æª”æä¾› SRT Subtitle Translator å„æ¨¡çµ„çš„è©³ç´°èªªæ˜ï¼Œé©åˆä»¥ä¸‹å ´æ™¯ï¼š

- ğŸ”§ æ•´åˆåˆ°è‡ªå·±çš„å°ˆæ¡ˆ
- ğŸ“¦ æ“´å±•åŠŸèƒ½
- ğŸ› å•é¡Œé™¤éŒ¯
- ğŸ§ª å–®å…ƒæ¸¬è©¦

### æ¶æ§‹æ¦‚è¦½

```
src/srt_translator/
â”œâ”€â”€ core/              # æ ¸å¿ƒæ¨¡çµ„
â”‚   â”œâ”€â”€ config.py      # ConfigManager
â”‚   â”œâ”€â”€ cache.py       # CacheManager
â”‚   â”œâ”€â”€ models.py      # ModelManager
â”‚   â””â”€â”€ prompt.py      # PromptManager
â”œâ”€â”€ translation/       # ç¿»è­¯æ¨¡çµ„
â”‚   â”œâ”€â”€ client.py      # TranslationClient
â”‚   â””â”€â”€ manager.py     # TranslationManager
â”œâ”€â”€ file_handling/     # æª”æ¡ˆè™•ç†
â”‚   â””â”€â”€ handler.py     # FileHandler
â”œâ”€â”€ services/          # æœå‹™å·¥å» 
â”‚   â””â”€â”€ factory.py     # ServiceFactory
â””â”€â”€ utils/             # å·¥å…·æ¨¡çµ„
    â”œâ”€â”€ errors.py
    â”œâ”€â”€ helpers.py
    â””â”€â”€ logging_config.py
```

---

## æ ¸å¿ƒæ¨¡çµ„ (core)

### ConfigManager

é…ç½®ç®¡ç†å™¨ï¼Œçµ±ä¸€ç®¡ç†æ‡‰ç”¨ç¨‹å¼çš„å„ç¨®é…ç½®ã€‚

#### é¡åˆ¥ç°½å

```python
class ConfigManager:
    """é…ç½®ç®¡ç†å™¨ï¼Œçµ±ä¸€ç®¡ç†ç³»çµ±çš„å„ç¨®é…ç½®"""
```

#### å»ºç«‹å¯¦ä¾‹

```python
from srt_translator.core.config import ConfigManager

# ç²å–å–®ä¾‹å¯¦ä¾‹
config_manager = ConfigManager.get_instance("user")
```

#### ä¸»è¦æ–¹æ³•

##### `get_instance(config_type: str) -> ConfigManager`

ç²å–é…ç½®ç®¡ç†å™¨å¯¦ä¾‹ï¼ˆå–®ä¾‹æ¨¡å¼ï¼‰ã€‚

**åƒæ•¸**ï¼š
- `config_type` (str): é…ç½®é¡å‹ï¼Œå¯é¸å€¼ï¼š
  - `"app"`: æ‡‰ç”¨ç¨‹å¼é…ç½®
  - `"user"`: ä½¿ç”¨è€…è¨­å®š
  - `"model"`: æ¨¡å‹é…ç½®
  - `"prompt"`: æç¤ºè©é…ç½®
  - `"file"`: æª”æ¡ˆè™•ç†é…ç½®
  - `"cache"`: å¿«å–é…ç½®

**å›å‚³**ï¼š`ConfigManager` - é…ç½®ç®¡ç†å™¨å¯¦ä¾‹

**ç¯„ä¾‹**ï¼š
```python
app_config = ConfigManager.get_instance("app")
user_config = ConfigManager.get_instance("user")
```

##### `get_config() -> Dict[str, Any]`

ç²å–å®Œæ•´é…ç½®ã€‚

**å›å‚³**ï¼š`Dict[str, Any]` - å®Œæ•´é…ç½®å­—å…¸

**ç¯„ä¾‹**ï¼š
```python
config = config_manager.get_config()
print(config["version"])
```

##### `get_value(key: str, default: Any = None) -> Any`

ç²å–å–®ä¸€é…ç½®å€¼ã€‚

**åƒæ•¸**ï¼š
- `key` (str): é…ç½®éµ
- `default` (Any, å¯é¸): é è¨­å€¼

**å›å‚³**ï¼š`Any` - é…ç½®å€¼

**ç¯„ä¾‹**ï¼š
```python
version = config_manager.get_value("version", "1.0.0")
debug_mode = config_manager.get_value("debug_mode", False)
```

##### `set_value(key: str, value: Any, auto_save: bool = True) -> None`

è¨­å®šé…ç½®å€¼ã€‚

**åƒæ•¸**ï¼š
- `key` (str): é…ç½®éµ
- `value` (Any): é…ç½®å€¼
- `auto_save` (bool): æ˜¯å¦è‡ªå‹•å„²å­˜ï¼Œé è¨­ True

**ç¯„ä¾‹**ï¼š
```python
config_manager.set_value("theme", "dark")
config_manager.set_value("debug_mode", True, auto_save=False)
```

##### `save_config() -> bool`

å„²å­˜é…ç½®åˆ°æª”æ¡ˆã€‚

**å›å‚³**ï¼š`bool` - æ˜¯å¦æˆåŠŸ

**ç¯„ä¾‹**ï¼š
```python
success = config_manager.save_config()
```

##### `reload_config() -> bool`

å¾æª”æ¡ˆé‡æ–°è¼‰å…¥é…ç½®ã€‚

**å›å‚³**ï¼š`bool` - æ˜¯å¦æˆåŠŸ

**ç¯„ä¾‹**ï¼š
```python
config_manager.reload_config()
```

#### å¿«æ·å‡½æ•¸

```python
from srt_translator.core.config import get_config, set_config

# å¿«é€Ÿç²å–é…ç½®
value = get_config("user", "theme", "default")

# å¿«é€Ÿè¨­å®šé…ç½®
set_config("user", "theme", "dark")
```

---

### CacheManager

ç¿»è­¯å¿«å–ç®¡ç†å™¨ï¼Œä½¿ç”¨ SQLite å„²å­˜ç¿»è­¯è¨˜æ†¶ã€‚

#### é¡åˆ¥ç°½å

```python
class CacheManager:
    """ç®¡ç†ç¿»è­¯ç·©å­˜çš„ SQLite æ•¸æ“šåº«"""
```

#### å»ºç«‹å¯¦ä¾‹

```python
from srt_translator.core.cache import CacheManager

cache_manager = CacheManager(db_path="data/translation_cache.db")
```

#### ä¸»è¦æ–¹æ³•

##### `__init__(db_path: str = "data/translation_cache.db")`

åˆå§‹åŒ–å¿«å–ç®¡ç†å™¨ã€‚

**åƒæ•¸**ï¼š
- `db_path` (str): SQLite è³‡æ–™åº«è·¯å¾‘

##### `get_cached_translation(text: str, context: List[str], model_name: str) -> Optional[str]`

å¾å¿«å–ç²å–ç¿»è­¯ã€‚

**åƒæ•¸**ï¼š
- `text` (str): è¦ç¿»è­¯çš„æ–‡æœ¬
- `context` (List[str]): ä¸Šä¸‹æ–‡åˆ—è¡¨
- `model_name` (str): æ¨¡å‹åç¨±

**å›å‚³**ï¼š`Optional[str]` - å¿«å–çš„ç¿»è­¯çµæœï¼Œæœªå‘½ä¸­å‰‡å›å‚³ None

**ç¯„ä¾‹**ï¼š
```python
translation = cache_manager.get_cached_translation(
    "Hello, world!",
    ["Previous subtitle"],
    "gpt-3.5-turbo"
)
```

##### `save_translation(text: str, translation: str, context: List[str], model_name: str) -> bool`

å„²å­˜ç¿»è­¯åˆ°å¿«å–ã€‚

**åƒæ•¸**ï¼š
- `text` (str): åŸå§‹æ–‡æœ¬
- `translation` (str): ç¿»è­¯çµæœ
- `context` (List[str]): ä¸Šä¸‹æ–‡åˆ—è¡¨
- `model_name` (str): æ¨¡å‹åç¨±

**å›å‚³**ï¼š`bool` - æ˜¯å¦æˆåŠŸ

**ç¯„ä¾‹**ï¼š
```python
cache_manager.save_translation(
    "Hello, world!",
    "ä½ å¥½ï¼Œä¸–ç•Œï¼",
    ["Previous subtitle"],
    "gpt-3.5-turbo"
)
```

##### `get_cache_stats() -> Dict[str, Any]`

ç²å–å¿«å–çµ±è¨ˆè³‡è¨Šã€‚

**å›å‚³**ï¼š`Dict[str, Any]` - å¿«å–çµ±è¨ˆ

**ç¯„ä¾‹**ï¼š
```python
stats = cache_manager.get_cache_stats()
print(f"ç¸½å¿«å–æ•¸: {stats['total_entries']}")
print(f"å¿«å–å¤§å°: {stats['size_mb']} MB")
```

##### `clear_cache(older_than_days: Optional[int] = None) -> int`

æ¸…ç†å¿«å–ã€‚

**åƒæ•¸**ï¼š
- `older_than_days` (Optional[int]): æ¸…ç†è¶…éæŒ‡å®šå¤©æ•¸çš„å¿«å–ï¼ŒNone å‰‡æ¸…é™¤å…¨éƒ¨

**å›å‚³**ï¼š`int` - åˆªé™¤çš„æ¢ç›®æ•¸

**ç¯„ä¾‹**ï¼š
```python
# æ¸…é™¤æ‰€æœ‰å¿«å–
deleted = cache_manager.clear_cache()

# æ¸…é™¤ 30 å¤©ä»¥å‰çš„å¿«å–
deleted = cache_manager.clear_cache(older_than_days=30)
```

---

### ModelManager

AI æ¨¡å‹ç®¡ç†å™¨ï¼Œç®¡ç†æ¨¡å‹æ¸…å–®å’Œæ¨è–¦ã€‚

#### é¡åˆ¥ç°½å

```python
class ModelManager:
    """ç®¡ç† AI æ¨¡å‹æ¸…å–®å’Œé¸æ“‡"""
```

#### å»ºç«‹å¯¦ä¾‹

```python
from srt_translator.core.models import ModelManager

model_manager = ModelManager()
```

#### ä¸»è¦æ–¹æ³•

##### `get_available_models(llm_type: str) -> List[str]`

ç²å–å¯ç”¨æ¨¡å‹åˆ—è¡¨ã€‚

**åƒæ•¸**ï¼š
- `llm_type` (str): LLM é¡å‹ ("ollama", "openai", "anthropic")

**å›å‚³**ï¼š`List[str]` - æ¨¡å‹åç¨±åˆ—è¡¨

**ç¯„ä¾‹**ï¼š
```python
# ç²å– OpenAI æ¨¡å‹
models = await model_manager.get_available_models("openai")
# ['gpt-3.5-turbo', 'gpt-4', 'gpt-4-turbo']

# ç²å– Ollama æœ¬åœ°æ¨¡å‹
models = await model_manager.get_available_models("ollama")
# ['llama2', 'mistral', 'codellama']
```

##### `get_recommended_model(task: str, llm_type: str) -> str`

ç²å–æ¨è–¦æ¨¡å‹ã€‚

**åƒæ•¸**ï¼š
- `task` (str): ä»»å‹™é¡å‹ ("translation", "summarization", etc.)
- `llm_type` (str): LLM é¡å‹

**å›å‚³**ï¼š`str` - æ¨è–¦çš„æ¨¡å‹åç¨±

**ç¯„ä¾‹**ï¼š
```python
model = model_manager.get_recommended_model("translation", "openai")
# 'gpt-3.5-turbo'
```

##### `validate_model(model_name: str, llm_type: str) -> bool`

é©—è­‰æ¨¡å‹æ˜¯å¦å¯ç”¨ã€‚

**åƒæ•¸**ï¼š
- `model_name` (str): æ¨¡å‹åç¨±
- `llm_type` (str): LLM é¡å‹

**å›å‚³**ï¼š`bool` - æ¨¡å‹æ˜¯å¦å¯ç”¨

**ç¯„ä¾‹**ï¼š
```python
is_valid = model_manager.validate_model("gpt-4", "openai")
```

---

### PromptManager

æç¤ºè©ç®¡ç†å™¨ï¼Œç®¡ç†ç¿»è­¯æç¤ºè©æ¨¡æ¿ã€‚

#### é¡åˆ¥ç°½å

```python
class PromptManager:
    """ç®¡ç†ç¿»è­¯æç¤ºè©"""
```

#### å»ºç«‹å¯¦ä¾‹

```python
from srt_translator.core.prompt import PromptManager

prompt_manager = PromptManager()
```

#### ä¸»è¦æ–¹æ³•

##### `get_prompt(llm_type: str, content_type: str = "general", style: str = "standard") -> str`

ç²å–ç¿»è­¯æç¤ºè©ã€‚

**åƒæ•¸**ï¼š
- `llm_type` (str): LLM é¡å‹
- `content_type` (str): å…§å®¹é¡å‹ ("general", "anime", "movie", "adult")
- `style` (str): ç¿»è­¯é¢¨æ ¼ ("standard", "literal", "localized", "specialized")

**å›å‚³**ï¼š`str` - æç¤ºè©æ–‡æœ¬

**ç¯„ä¾‹**ï¼š
```python
# ä¸€èˆ¬å…§å®¹æ¨™æº–ç¿»è­¯
prompt = prompt_manager.get_prompt("openai", "general", "standard")

# å‹•ç•«å…§å®¹æœ¬åœ°åŒ–ç¿»è­¯
prompt = prompt_manager.get_prompt("openai", "anime", "localized")
```

##### `set_prompt(llm_type: str, content_type: str, style: str, prompt: str) -> bool`

è¨­å®šè‡ªè¨‚æç¤ºè©ã€‚

**åƒæ•¸**ï¼š
- `llm_type` (str): LLM é¡å‹
- `content_type` (str): å…§å®¹é¡å‹
- `style` (str): ç¿»è­¯é¢¨æ ¼
- `prompt` (str): æç¤ºè©æ–‡æœ¬

**å›å‚³**ï¼š`bool` - æ˜¯å¦æˆåŠŸ

**ç¯„ä¾‹**ï¼š
```python
custom_prompt = """Translate the following subtitle to Traditional Chinese.
Focus on natural expression and cultural adaptation."""

prompt_manager.set_prompt("openai", "movie", "standard", custom_prompt)
```

##### `get_all_content_types() -> List[str]`

ç²å–æ‰€æœ‰å…§å®¹é¡å‹ã€‚

**å›å‚³**ï¼š`List[str]` - å…§å®¹é¡å‹åˆ—è¡¨

**ç¯„ä¾‹**ï¼š
```python
types = prompt_manager.get_all_content_types()
# ['general', 'anime', 'movie', 'adult']
```

---

## ç¿»è­¯æ¨¡çµ„ (translation)

### TranslationClient

ç¿»è­¯ API å®¢æˆ¶ç«¯ï¼Œå°è£å„ç¨® AI å¼•æ“çš„ API å‘¼å«ã€‚

#### é¡åˆ¥ç°½å

```python
class TranslationClient:
    """ç¿»è­¯å®¢æˆ¶ç«¯ï¼Œå°è£ API å‘¼å«"""
```

#### å»ºç«‹å¯¦ä¾‹

```python
from srt_translator.translation.client import TranslationClient

client = TranslationClient(
    llm_type="openai",
    model_name="gpt-3.5-turbo",
    api_key="your-api-key"
)
```

#### ä¸»è¦æ–¹æ³•

##### `__init__(llm_type: str, model_name: str, api_key: Optional[str] = None)`

åˆå§‹åŒ–ç¿»è­¯å®¢æˆ¶ç«¯ã€‚

**åƒæ•¸**ï¼š
- `llm_type` (str): LLM é¡å‹ ("ollama", "openai", "anthropic")
- `model_name` (str): æ¨¡å‹åç¨±
- `api_key` (Optional[str]): API é‡‘é‘°ï¼ˆOllama ä¸éœ€è¦ï¼‰

##### `translate(text: str, source_lang: str, target_lang: str, context: Optional[List[str]] = None) -> str`

ç¿»è­¯æ–‡æœ¬ã€‚

**åƒæ•¸**ï¼š
- `text` (str): è¦ç¿»è­¯çš„æ–‡æœ¬
- `source_lang` (str): æºèªè¨€
- `target_lang` (str): ç›®æ¨™èªè¨€
- `context` (Optional[List[str]]): ä¸Šä¸‹æ–‡åˆ—è¡¨

**å›å‚³**ï¼š`str` - ç¿»è­¯çµæœ

**ç¯„ä¾‹**ï¼š
```python
translation = await client.translate(
    "Hello, world!",
    "English",
    "Traditional Chinese",
    context=["Previous subtitle here"]
)
# 'ä½ å¥½ï¼Œä¸–ç•Œï¼'
```

##### `translate_batch(texts: List[str], source_lang: str, target_lang: str, concurrent_limit: int = 5) -> List[str]`

æ‰¹é‡ç¿»è­¯ã€‚

**åƒæ•¸**ï¼š
- `texts` (List[str]): è¦ç¿»è­¯çš„æ–‡æœ¬åˆ—è¡¨
- `source_lang` (str): æºèªè¨€
- `target_lang` (str): ç›®æ¨™èªè¨€
- `concurrent_limit` (int): ä¸¦ç™¼é™åˆ¶

**å›å‚³**ï¼š`List[str]` - ç¿»è­¯çµæœåˆ—è¡¨

**ç¯„ä¾‹**ï¼š
```python
texts = ["Hello", "World", "How are you?"]
translations = await client.translate_batch(
    texts,
    "English",
    "Traditional Chinese",
    concurrent_limit=3
)
# ['ä½ å¥½', 'ä¸–ç•Œ', 'ä½ å¥½å—ï¼Ÿ']
```

---

### TranslationManager

ç¿»è­¯æµç¨‹ç®¡ç†å™¨ï¼Œå”èª¿ç¿»è­¯éç¨‹ã€‚

#### é¡åˆ¥ç°½å

```python
class TranslationManager:
    """ç®¡ç†ç¿»è­¯æµç¨‹"""
```

#### å»ºç«‹å¯¦ä¾‹

```python
from srt_translator.translation.manager import TranslationManager

manager = TranslationManager()
```

#### ä¸»è¦æ–¹æ³•

##### `translate_file(input_path: str, output_path: str, source_lang: str, target_lang: str, llm_type: str, model_name: str, display_mode: str = "bilingual", progress_callback: Optional[Callable] = None) -> bool`

ç¿»è­¯æ•´å€‹å­—å¹•æª”æ¡ˆã€‚

**åƒæ•¸**ï¼š
- `input_path` (str): è¼¸å…¥æª”æ¡ˆè·¯å¾‘
- `output_path` (str): è¼¸å‡ºæª”æ¡ˆè·¯å¾‘
- `source_lang` (str): æºèªè¨€
- `target_lang` (str): ç›®æ¨™èªè¨€
- `llm_type` (str): LLM é¡å‹
- `model_name` (str): æ¨¡å‹åç¨±
- `display_mode` (str): é¡¯ç¤ºæ¨¡å¼
- `progress_callback` (Optional[Callable]): é€²åº¦å›èª¿å‡½æ•¸

**å›å‚³**ï¼š`bool` - æ˜¯å¦æˆåŠŸ

**ç¯„ä¾‹**ï¼š
```python
def on_progress(current, total):
    print(f"é€²åº¦: {current}/{total}")

success = await manager.translate_file(
    "input.srt",
    "output.srt",
    "Japanese",
    "Traditional Chinese",
    "openai",
    "gpt-3.5-turbo",
    display_mode="bilingual",
    progress_callback=on_progress
)
```

---

## æª”æ¡ˆè™•ç†æ¨¡çµ„ (file_handling)

### FileHandler

å­—å¹•æª”æ¡ˆè™•ç†å™¨ï¼Œè™•ç†æª”æ¡ˆçš„è®€å–ã€è§£æå’Œå„²å­˜ã€‚

#### é¡åˆ¥ç°½å

```python
class FileHandler:
    """è™•ç†å­—å¹•æª”æ¡ˆçš„è®€å–ã€è§£æå’Œå„²å­˜"""
```

#### å»ºç«‹å¯¦ä¾‹

```python
from srt_translator.file_handling.handler import FileHandler

file_handler = FileHandler()
```

#### ä¸»è¦æ–¹æ³•

##### `read_subtitle_file(file_path: str) -> SubtitleInfo`

è®€å–å­—å¹•æª”æ¡ˆã€‚

**åƒæ•¸**ï¼š
- `file_path` (str): æª”æ¡ˆè·¯å¾‘

**å›å‚³**ï¼š`SubtitleInfo` - å­—å¹•è³‡è¨Šç‰©ä»¶

**ç¯„ä¾‹**ï¼š
```python
subtitle_info = file_handler.read_subtitle_file("input.srt")
print(f"å­—å¹•æ•¸é‡: {len(subtitle_info.subtitles)}")
print(f"æª”æ¡ˆæ ¼å¼: {subtitle_info.format}")
```

##### `write_subtitle_file(file_path: str, subtitles: List[Subtitle], format: str = "srt") -> bool`

å¯«å…¥å­—å¹•æª”æ¡ˆã€‚

**åƒæ•¸**ï¼š
- `file_path` (str): è¼¸å‡ºè·¯å¾‘
- `subtitles` (List[Subtitle]): å­—å¹•åˆ—è¡¨
- `format` (str): æª”æ¡ˆæ ¼å¼

**å›å‚³**ï¼š`bool` - æ˜¯å¦æˆåŠŸ

**ç¯„ä¾‹**ï¼š
```python
success = file_handler.write_subtitle_file(
    "output.srt",
    translated_subtitles,
    format="srt"
)
```

##### `detect_encoding(file_path: str) -> str`

åµæ¸¬æª”æ¡ˆç·¨ç¢¼ã€‚

**åƒæ•¸**ï¼š
- `file_path` (str): æª”æ¡ˆè·¯å¾‘

**å›å‚³**ï¼š`str` - ç·¨ç¢¼åç¨±

**ç¯„ä¾‹**ï¼š
```python
encoding = file_handler.detect_encoding("input.srt")
# 'utf-8'
```

---

## æœå‹™å·¥å»  (services)

### ServiceFactory

æœå‹™å·¥å» ï¼Œçµ±ä¸€ç®¡ç†æ‰€æœ‰æœå‹™å¯¦ä¾‹ï¼ˆå–®ä¾‹æ¨¡å¼ï¼‰ã€‚

#### é¡åˆ¥ç°½å

```python
class ServiceFactory:
    """æœå‹™å·¥å» é¡ï¼Œç®¡ç†æ‰€æœ‰æœå‹™å¯¦ä¾‹"""
```

#### ä¸»è¦æ–¹æ³•

##### `get_translation_service() -> TranslationService`

ç²å–ç¿»è­¯æœå‹™å¯¦ä¾‹ã€‚

**å›å‚³**ï¼š`TranslationService` - ç¿»è­¯æœå‹™

**ç¯„ä¾‹**ï¼š
```python
from srt_translator.services.factory import ServiceFactory

translation_service = ServiceFactory.get_translation_service()
```

##### `get_model_service() -> ModelService`

ç²å–æ¨¡å‹æœå‹™å¯¦ä¾‹ã€‚

**å›å‚³**ï¼š`ModelService` - æ¨¡å‹æœå‹™

**ç¯„ä¾‹**ï¼š
```python
model_service = ServiceFactory.get_model_service()
models = await model_service.get_available_models("openai")
```

##### `get_cache_service() -> CacheService`

ç²å–å¿«å–æœå‹™å¯¦ä¾‹ã€‚

**å›å‚³**ï¼š`CacheService` - å¿«å–æœå‹™

**ç¯„ä¾‹**ï¼š
```python
cache_service = ServiceFactory.get_cache_service()
stats = cache_service.get_cache_stats()
```

##### `get_file_service() -> FileService`

ç²å–æª”æ¡ˆæœå‹™å¯¦ä¾‹ã€‚

**å›å‚³**ï¼š`FileService` - æª”æ¡ˆæœå‹™

**ç¯„ä¾‹**ï¼š
```python
file_service = ServiceFactory.get_file_service()
subtitle_info = file_service.read_subtitle_file("input.srt")
```

##### `reset_services() -> None`

é‡ç½®æ‰€æœ‰æœå‹™å¯¦ä¾‹ï¼ˆæ¸…ç†è³‡æºï¼‰ã€‚

**ç¯„ä¾‹**ï¼š
```python
# æ‡‰ç”¨ç¨‹å¼é—œé–‰æ™‚å‘¼å«
ServiceFactory.reset_services()
```

---

## å·¥å…·æ¨¡çµ„ (utils)

### éŒ¯èª¤é¡åˆ¥

#### AppError

æ‡‰ç”¨ç¨‹å¼åŸºç¤éŒ¯èª¤é¡åˆ¥ã€‚

```python
from srt_translator.utils.errors import AppError

class AppError(Exception):
    """æ‡‰ç”¨ç¨‹å¼åŸºç¤éŒ¯èª¤"""
```

#### TranslationError

ç¿»è­¯ç›¸é—œéŒ¯èª¤ã€‚

```python
from srt_translator.utils.errors import TranslationError

class TranslationError(AppError):
    """ç¿»è­¯éç¨‹éŒ¯èª¤"""
```

#### FileHandlingError

æª”æ¡ˆè™•ç†éŒ¯èª¤ã€‚

```python
from srt_translator.utils.errors import FileHandlingError

class FileHandlingError(AppError):
    """æª”æ¡ˆè™•ç†éŒ¯èª¤"""
```

#### APIError

API å‘¼å«éŒ¯èª¤ã€‚

```python
from srt_translator.utils.errors import APIError

class APIError(AppError):
    """API å‘¼å«éŒ¯èª¤"""
```

### è¼”åŠ©å‡½æ•¸

#### `safe_execute(func: Callable, *args, **kwargs) -> Tuple[bool, Any, Optional[Exception]]`

å®‰å…¨åŸ·è¡Œå‡½æ•¸ï¼Œæ•ç²ç•°å¸¸ã€‚

**åƒæ•¸**ï¼š
- `func` (Callable): è¦åŸ·è¡Œçš„å‡½æ•¸
- `*args`: ä½ç½®åƒæ•¸
- `**kwargs`: é—œéµå­—åƒæ•¸

**å›å‚³**ï¼š`Tuple[bool, Any, Optional[Exception]]` - (æˆåŠŸ, çµæœ, ç•°å¸¸)

**ç¯„ä¾‹**ï¼š
```python
from srt_translator.utils import safe_execute

success, result, error = safe_execute(risky_function, arg1, arg2)
if success:
    print(f"çµæœ: {result}")
else:
    print(f"éŒ¯èª¤: {error}")
```

#### `format_exception(e: Exception) -> str`

æ ¼å¼åŒ–ç•°å¸¸è¨Šæ¯ã€‚

**åƒæ•¸**ï¼š
- `e` (Exception): ç•°å¸¸ç‰©ä»¶

**å›å‚³**ï¼š`str` - æ ¼å¼åŒ–çš„éŒ¯èª¤è¨Šæ¯

**ç¯„ä¾‹**ï¼š
```python
from srt_translator.utils import format_exception

try:
    # some code
except Exception as e:
    error_msg = format_exception(e)
    logger.error(error_msg)
```

#### `check_internet_connection() -> bool`

æª¢æŸ¥ç¶²è·¯é€£æ¥ã€‚

**å›å‚³**ï¼š`bool` - æ˜¯å¦é€£æ¥ç¶²è·¯

**ç¯„ä¾‹**ï¼š
```python
from srt_translator.utils import check_internet_connection

if not check_internet_connection():
    print("ç„¡ç¶²è·¯é€£æ¥")
```

---

## ä½¿ç”¨ç¯„ä¾‹

### ç¯„ä¾‹ 1ï¼šç°¡å–®ç¿»è­¯æµç¨‹

```python
import asyncio
from srt_translator.services.factory import ServiceFactory

async def translate_file():
    # ç²å–æœå‹™
    translation_service = ServiceFactory.get_translation_service()
    file_service = ServiceFactory.get_file_service()

    # è®€å–å­—å¹•
    subtitle_info = file_service.read_subtitle_file("input.srt")

    # ç¿»è­¯
    translated = await translation_service.translate_text(
        subtitle_info.subtitles[0].text,
        ["Previous context"],
        "openai",
        "gpt-3.5-turbo"
    )

    print(f"ç¿»è­¯çµæœ: {translated}")

# åŸ·è¡Œ
asyncio.run(translate_file())
```

### ç¯„ä¾‹ 2ï¼šä½¿ç”¨å¿«å–

```python
from srt_translator.core.cache import CacheManager

cache_manager = CacheManager()

# å˜—è©¦å¾å¿«å–ç²å–
cached = cache_manager.get_cached_translation(
    "Hello",
    [],
    "gpt-3.5-turbo"
)

if cached:
    print(f"å¿«å–å‘½ä¸­: {cached}")
else:
    # ç¿»è­¯ä¸¦å„²å­˜åˆ°å¿«å–
    translation = await translate("Hello")
    cache_manager.save_translation(
        "Hello",
        translation,
        [],
        "gpt-3.5-turbo"
    )
```

### ç¯„ä¾‹ 3ï¼šè‡ªè¨‚é…ç½®

```python
from srt_translator.core.config import ConfigManager

# ç²å–é…ç½®ç®¡ç†å™¨
config = ConfigManager.get_instance("user")

# è¨­å®šè‡ªè¨‚å€¼
config.set_value("theme", "dark")
config.set_value("parallel_requests", 10)
config.set_value("auto_save", True)

# å„²å­˜é…ç½®
config.save_config()
```

### ç¯„ä¾‹ 4ï¼šæ‰¹é‡è™•ç†

```python
import asyncio
from srt_translator.translation.client import TranslationClient

async def batch_translate():
    client = TranslationClient("openai", "gpt-3.5-turbo", "your-api-key")

    texts = [
        "Hello, world!",
        "How are you?",
        "Nice to meet you."
    ]

    results = await client.translate_batch(
        texts,
        "English",
        "Traditional Chinese",
        concurrent_limit=3
    )

    for original, translated in zip(texts, results):
        print(f"{original} â†’ {translated}")

asyncio.run(batch_translate())
```

---

## æœ€ä½³å¯¦è¸

### 1. ä½¿ç”¨æœå‹™å·¥å» 

å§‹çµ‚é€é `ServiceFactory` ç²å–æœå‹™å¯¦ä¾‹ï¼Œç¢ºä¿å–®ä¾‹æ¨¡å¼ï¼š

```python
# âœ… æ­£ç¢º
translation_service = ServiceFactory.get_translation_service()

# âŒ éŒ¯èª¤ï¼ˆä¸å»ºè­°ï¼‰
translation_service = TranslationService()
```

### 2. éŒ¯èª¤è™•ç†

ä½¿ç”¨å°ˆæ¡ˆæä¾›çš„éŒ¯èª¤é¡åˆ¥å’Œè¼”åŠ©å‡½æ•¸ï¼š

```python
from srt_translator.utils import safe_execute, format_exception
from srt_translator.utils.errors import TranslationError

try:
    result = await translate(text)
except TranslationError as e:
    logger.error(format_exception(e))
```

### 3. éåŒæ­¥æ“ä½œ

ç¿»è­¯æ“ä½œæ˜¯éåŒæ­¥çš„ï¼Œå‹™å¿…ä½¿ç”¨ `async/await`ï¼š

```python
# âœ… æ­£ç¢º
translation = await client.translate(text, source_lang, target_lang)

# âŒ éŒ¯èª¤
translation = client.translate(text, source_lang, target_lang)
```

### 4. è³‡æºæ¸…ç†

æ‡‰ç”¨ç¨‹å¼é—œé–‰æ™‚æ¸…ç†è³‡æºï¼š

```python
# åœ¨æ‡‰ç”¨ç¨‹å¼çµæŸæ™‚
ServiceFactory.reset_services()
```

### 5. é…ç½®ç®¡ç†

ä½¿ç”¨é…ç½®ç®¡ç†å™¨é›†ä¸­ç®¡ç†é…ç½®ï¼š

```python
# âœ… æ­£ç¢º
from srt_translator.core.config import get_config
theme = get_config("user", "theme", "default")

# âŒ éŒ¯èª¤ï¼ˆç¡¬ç·¨ç¢¼ï¼‰
theme = "dark"
```

---

## å‹åˆ¥æç¤º

æœ¬å°ˆæ¡ˆæ”¯æ´å‹åˆ¥æç¤ºï¼Œå»ºè­°ä½¿ç”¨ mypy é€²è¡Œå‹åˆ¥æª¢æŸ¥ï¼š

```bash
uv run mypy src/srt_translator
```

---

**æœ€å¾Œæ›´æ–°**ï¼š2025-01-28
**ç‰ˆæœ¬**ï¼š1.0.0
