import json
import logging
import logging.handlers
import os
import re
import threading
from datetime import datetime
from typing import Any, Dict, List, Optional

# å¾é…ç½®ç®¡ç†å™¨å°å…¥
from srt_translator.core.config import ConfigManager, get_config
from srt_translator.utils import format_exception

# è¨­å®šæ—¥èªŒè¨˜éŒ„
logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG)

# ç¢ºä¿æ—¥èªŒç›®éŒ„å­˜åœ¨
os.makedirs("logs", exist_ok=True)

# é¿å…é‡è¤‡æ·»åŠ è™•ç†ç¨‹åº
if not logger.handlers:
    handler = logging.handlers.TimedRotatingFileHandler(
        filename="logs/prompt_manager.log", when="midnight", interval=1, backupCount=7, encoding="utf-8"
    )
    formatter = logging.Formatter("%(asctime)s - %(levelname)s - %(filename)s:%(lineno)d - %(message)s")
    handler.setFormatter(formatter)
    logger.addHandler(handler)


class PromptManager:
    """æç¤ºè©ç®¡ç†å™¨ï¼Œè² è²¬ç®¡ç†ç¿»è­¯æç¤ºè©æ¨¡æ¿å’Œè¨­å®š"""

    # é¡è®Šæ•¸ï¼Œç”¨æ–¼å¯¦ç¾å–®ä¾‹æ¨¡å¼
    _instance = None
    _lock = threading.Lock()

    @classmethod
    def get_instance(cls, config_file: Optional[str] = None) -> "PromptManager":
        """ç²å–æç¤ºè©ç®¡ç†å™¨çš„å–®ä¾‹å¯¦ä¾‹

        åƒæ•¸:
            config_file: é…ç½®æª”æ¡ˆè·¯å¾‘ï¼Œè‹¥ç‚ºNoneå‰‡ä½¿ç”¨é è¨­è·¯å¾‘

        å›å‚³:
            æç¤ºè©ç®¡ç†å™¨å¯¦ä¾‹
        """
        with cls._lock:
            if cls._instance is None:
                # å¦‚æœæ²’æœ‰æŒ‡å®šconfig_fileï¼Œå¾é…ç½®ç²å–
                if config_file is None:
                    config_file = get_config("prompt", "config_file", "config/prompt_config.json")

                cls._instance = PromptManager(config_file)
            return cls._instance

    def __init__(self, config_file: str = "config/prompt_config.json"):
        """åˆå§‹åŒ–æç¤ºè©ç®¡ç†å™¨

        åƒæ•¸:
            config_file: é…ç½®æª”æ¡ˆè·¯å¾‘
        """
        self.config_file = config_file
        self.config_dir = os.path.dirname(config_file) or "."
        self.templates_dir = os.path.join(self.config_dir, "prompt_templates")

        # ç¢ºä¿æ¨¡æ¿ç›®éŒ„å­˜åœ¨
        os.makedirs(self.templates_dir, exist_ok=True)

        # ç²å–é…ç½®ç®¡ç†å™¨å¯¦ä¾‹
        self.config_manager = ConfigManager.get_instance("prompt")

        # ç¿»è­¯é¢¨æ ¼å®šç¾©
        self.translation_styles = {
            "standard": "æ¨™æº–ç¿»è­¯ - å¹³è¡¡æº–ç¢ºæ€§å’Œè‡ªç„¶åº¦",
            "literal": "ç›´è­¯ - æ›´å¿ æ–¼åŸæ–‡çš„å­—é¢æ„æ€",
            "localized": "æœ¬åœ°åŒ–ç¿»è­¯ - æ›´é©åˆå°ç£ç¹é«”ä¸­æ–‡æ–‡åŒ–",
            "specialized": "å°ˆæ¥­ç¿»è­¯ - ä¿ç•™å°ˆæ¥­è¡“èª",
        }

        # èªè¨€çµ„åˆæ˜ å°„
        self.language_pairs = {
            "æ—¥æ–‡â†’ç¹é«”ä¸­æ–‡": {"source": "æ—¥æ–‡", "target": "ç¹é«”ä¸­æ–‡"},
            "è‹±æ–‡â†’ç¹é«”ä¸­æ–‡": {"source": "è‹±æ–‡", "target": "ç¹é«”ä¸­æ–‡"},
            "ç¹é«”ä¸­æ–‡â†’è‹±æ–‡": {"source": "ç¹é«”ä¸­æ–‡", "target": "è‹±æ–‡"},
            "éŸ“æ–‡â†’ç¹é«”ä¸­æ–‡": {"source": "éŸ“æ–‡", "target": "ç¹é«”ä¸­æ–‡"},
            "æ³•æ–‡â†’ç¹é«”ä¸­æ–‡": {"source": "æ³•æ–‡", "target": "ç¹é«”ä¸­æ–‡"},
            "å¾·æ–‡â†’ç¹é«”ä¸­æ–‡": {"source": "å¾·æ–‡", "target": "ç¹é«”ä¸­æ–‡"},
            "è¥¿ç­ç‰™æ–‡â†’ç¹é«”ä¸­æ–‡": {"source": "è¥¿ç­ç‰™æ–‡", "target": "ç¹é«”ä¸­æ–‡"},
            "ä¿„æ–‡â†’ç¹é«”ä¸­æ–‡": {"source": "ä¿„æ–‡", "target": "ç¹é«”ä¸­æ–‡"},
        }

        # é è¨­æç¤ºè©
        self.default_prompts = self._get_default_prompts()

        # è¼‰å…¥è¨­å®š
        self._load_config()

        # è¨­å®šç•¶å‰ä½¿ç”¨çš„å…§å®¹é¡å‹å’Œé¢¨æ ¼
        self.current_content_type = self.config_manager.get_value("current_content_type", "general")
        self.current_style = self.config_manager.get_value("current_style", "standard")
        self.current_language_pair = self.config_manager.get_value("current_language_pair", "æ—¥æ–‡â†’ç¹é«”ä¸­æ–‡")

        # è¼‰å…¥ç‰ˆæœ¬æ­·å²
        self.version_history: Dict[str, Any] = self.config_manager.get_value("version_history", default={}) or {}

        # è¼‰å…¥è‡ªè¨‚æç¤ºè©
        self.custom_prompts: Dict[str, Any] = self.config_manager.get_value("custom_prompts", default={}) or {}
        self._load_custom_prompts()

        # è¨­ç½®é…ç½®è®Šæ›´ç›£è½å™¨
        self.config_manager.add_listener(self._config_changed)

        logger.info("PromptManager åˆå§‹åŒ–å®Œæˆ")

    def _get_default_prompts(self) -> Dict[str, Dict[str, str]]:
        """ç²å–é è¨­æç¤ºè©ï¼Œå¾é…ç½®æª”æ¡ˆæˆ–å…§ç½®é è¨­å€¼"""
        # å˜—è©¦å¾é…ç½®ç²å–é è¨­æç¤ºè©
        default_config = ConfigManager.get_instance("default_prompt")
        default_prompts = default_config.get_value("default_prompts", None)

        if default_prompts:
            return dict(default_prompts)

        # å¦‚æœé…ç½®ä¸­æ²’æœ‰ï¼Œä½¿ç”¨å…§ç½®é è¨­å€¼

        # ========== æ ¸å¿ƒå¯é‡ç”¨æ¨¡çµ„ ==========

        # äººåä¿ç•™è¦å‰‡æ¨¡çµ„ï¼ˆé©ç”¨æ–¼æ‰€æœ‰è‹±èªå…§å®¹ï¼‰
        name_preservation_rules = """
## Personal Names - Critical Rule (ABSOLUTE REQUIREMENT):
**Keep ALL English personal names in their original English form. NEVER translate or transliterate names into Chinese.**

âœ… **CORRECT Examples:**
- "Kylie Estevez" â†’ Keep as "Kylie Estevez"
- "Sylvie Brett" â†’ Keep as "Sylvie Brett"
- "Severide" â†’ Keep as "Severide"
- "Dr. Smith" â†’ "Smithé†«ç”Ÿ" (translate title, keep name)

âŒ **INCORRECT Examples:**
- "Kylie Estevez" â†’ ~~"å‡±è‰Â·è‰¾æ–¯ç‰¹ç¶­èŒ²"~~ (NO transliteration)
- "Brett" â†’ ~~"å¸ƒé›·ç‰¹"~~ (NO transliteration)

**When titles/honorifics are combined with names:**
- Translate the title, keep the name in English
- "Aunt Lacey" â†’ "Laceyé˜¿å§¨" (aunt = é˜¿å§¨)
- "Lieutenant LeClerc" â†’ "å‰¯éšŠé•·LeClerc" (lieutenant = å‰¯éšŠé•·)
"""

        # å°å¼å£èªè¡¨é”æ¨¡çµ„ï¼ˆé©ç”¨æ–¼æ‰€æœ‰ç¹ä¸­ç¿»è­¯ï¼‰
        taiwanese_colloquial = """
## Taiwanese Colloquial Expression Guidelines:
Use natural Taiwanese Mandarin, avoiding Mainland Chinese expressions or overly formal language.

**Style Guidelines:**
| Taiwanese Style âœ… | Avoid âŒ |
|-------------------|---------|
| ä½ é‚„å¥½å— | ä½ æ²’äº‹å§ |
| ä¿¡æˆ‘ | ç›¸ä¿¡æˆ‘ |
| æ€éº¼é‚£éº¼å¤šäºº | ç‚ºä»€éº¼é€™éº¼å¤šäºº |
| æ··äº‚å¾—è¦å‘½ | éå¸¸æ··äº‚ |
| è©±èªªå›ä¾† | ä½†æ˜¯ |
| å° | æ˜¯çš„ |
| ä¸æœƒå§ | ä¸å¯èƒ½å§ |

**Key Characteristics:**
- Conversational and natural
- Concise without being abrupt
- Matches spoken Taiwanese Mandarin patterns
- Culturally appropriate for Taiwan audience
"""

        # Netflix ç¹é«”ä¸­æ–‡å­—å¹•è¦ç¯„ï¼ˆå…±ç”¨éƒ¨åˆ†ï¼‰
        netflix_rules = """

## Netflix Traditional Chinese Subtitle Standards (MUST FOLLOW):

**Punctuation**:
- Use full-width Chinese punctuation: ï¼Œã€ï¼šã€ï¼›ã€ï¼ã€ï¼Ÿã€ã€Œã€ã€ã€ã€
- DO NOT use any period or comma at the end of lines
- Use ellipsis â‹¯ (U+2026), not ... or ã€‚ã€‚ã€‚
- Question marks are required, do not omit
- DO NOT use double question marks (??) or double exclamation marks (!!)

**Quotation Marks**:
- Useã€Œã€for direct quotes
- Useã€ã€for quotes within quotes
- Add quotation marks to each subtitle event when quotes span multiple subtitles

**Continuity**:
- When splitting sentences across continuous subtitles, do NOT use ellipsis or dashes
- Only use ellipsis (â‹¯) for pauses or abrupt interruptions
- Use leading ellipsis for mid-sentence starts (â‹¯å¾ˆæœ‰æ„æ€)

**Numbers**:
- Use half-width numbers (1, 2, 3), not full-width (ï¼‘ï¼Œï¼’ï¼Œï¼“)
- No comma separator for 4-digit numbers
- Do NOT mix Arabic numerals with Chinese number characters
- Use Chinese for days of week (æ˜ŸæœŸäºŒ, not æ˜ŸæœŸ2)

**Character Limit (CRITICAL)**:
âš ï¸ **STRICT REQUIREMENT: Each line MUST NOT exceed 16 Traditional Chinese characters (including punctuation)**
- Maximum 16 characters per line (çµ•å°ä¸å¯è¶…éï¼)
- Maximum 2 lines per subtitle
- If original text is too long, split into multiple lines (each â‰¤ 16 chars)
- Prioritize concise expressions and natural line breaks
- Keep reading speed at 9 chars/sec for adult content

**Examples**:
âŒ BAD: æ‰€æœ‰æ°‘ä¸»é»¨äººæƒ³åšçš„å°±æ˜¯ä¸æ“‡æ‰‹æ®µåœ°ç ´å£ç‰¹æœ—æ™®çš„ç¹æ¦®
âœ… GOOD (split into 2 lines):
  æ‰€æœ‰æ°‘ä¸»é»¨äººæƒ³åšçš„
  å°±æ˜¯ä¸æ“‡æ‰‹æ®µåœ°ç ´å£

âŒ BAD: æˆ‘å¾ä¾†æ²’æœ‰è¦‹éé€™éº¼è’è¬¬çš„äº‹æƒ…
âœ… GOOD (split into 2 lines):
  æˆ‘å¾ä¾†æ²’è¦‹é
  é€™éº¼è’è¬¬çš„äº‹

**Translation Quality**:
- Use Taiwan Traditional Chinese
- Use gender-neutralã€Œä½ ã€for second person
- Specify gender for third person pronouns (ä»–ã€å¥¹ã€ç‰ ã€ç¥‚ã€å®ƒ)
- Avoid regional dialects (Hokkien, Cantonese, etc.)
- Match original tone, register, and formality
- Never censor profanity - translate faithfully
"""

        return {
            "general": {
                "ollama": f"""
You are a professional subtitle translator. Your task is to translate subtitles accurately.
Please strictly follow these rules:
1. Only translate the CURRENT text sent to you, NOT any context text.
2. Preserve the exact number of lines in the original text.
3. Keep all formatting, including newlines, in the exact same positions.
4. Maintain the original tone and expression style.
5. Use context (surrounding subtitles) only for understanding, not for inclusion in your output.
6. Translate into natural Taiwan Mandarin Chinese expressions.
7. Your response must contain ONLY the translated text, nothing else.
{taiwanese_colloquial}
{netflix_rules}
""",
                "openai": f"""
You are a high-efficiency subtitle translator. Your task:
1. ONLY translate the CURRENT text, nothing else. No warnings, explanations, or quotes.
2. Preserve the exact number of lines and formatting of the original.
3. Maintain original tone and style. Translate to Taiwan Mandarin.
4. Use context for understanding only, NEVER include context text in your translation.
5. Be concise and direct - output ONLY the translated text.
{taiwanese_colloquial}
{netflix_rules}
""",
            },
            "adult": {
                "ollama": f"""
You are a professional translator for adult video subtitles.
Please strictly follow these rules:
1. Only translate the CURRENT text sent to you, NOT any context text.
2. Preserve the exact number of lines in the original text.
3. Keep all formatting, including newlines, in the exact same positions.
4. Maintain the original tone and expression style.
5. Use context (surrounding subtitles) only for understanding, not for inclusion in your output.
6. Translate into natural Taiwan Mandarin Chinese expressions with appropriate adult terminology.
7. Your response must contain ONLY the translated text, nothing else.
{taiwanese_colloquial}
{netflix_rules}
""",
                "openai": f"""
You are a high-efficiency adult content subtitle translator. Your task:
1. ONLY translate the CURRENT text, nothing else. No warnings, explanations, or quotes.
2. Preserve the exact number of lines and formatting of the original.
3. Maintain original tone and style. Translate to Taiwan Mandarin.
4. Use appropriate adult terminology in the target language.
5. Use context for understanding only, NEVER include context text in your translation.
6. Be direct and accurate - output ONLY the translated text.
{taiwanese_colloquial}
{netflix_rules}
""",
            },
            "anime": {
                "ollama": f"""
You are a professional anime subtitle translator.
Please strictly follow these rules:
1. Only translate the CURRENT text sent to you, NOT any context text.
2. Preserve the exact number of lines in the original text.
3. Keep all formatting, including newlines, in the exact same positions.
4. Maintain the original tone and expression style.
5. Preserve anime-specific terminology, character names, and Japanese honorifics.
6. Translate into natural Taiwan Mandarin Chinese expressions that anime fans would appreciate.
7. Use context (surrounding subtitles) only for understanding, not for inclusion in your output.
8. Your response must contain ONLY the translated text, nothing else.

## Anime-Specific Guidelines:
**Character Names:**
- Keep Japanese character names in romaji or original form
- Preserve honorifics: -san, -kun, -chan, -sama, -senpai, -sensei
- Examples: "Naruto-kun", "Sakura-chan", "Kakashi-sensei"

**Anime Terminology:**
- Keep common anime terms: "kawaii", "baka", "senpai", "kouhai"
- Translate action terms naturally: "å¿…æ®ºæŠ€" for special moves
- Preserve attack names in original language when iconic

{taiwanese_colloquial}
{netflix_rules}
""",
                "openai": f"""
You are an anime subtitle translator. Your task:
1. ONLY translate the CURRENT text, nothing else. No warnings or explanations.
2. Preserve the exact number of lines and formatting of the original.
3. Maintain original tone and Japanese expression style.
4. Preserve anime terms, character names, and honorifics (-san, -kun, etc.).
5. Translate to Taiwan Mandarin using anime-appropriate language.
6. Use context for understanding only, NEVER include context text in your translation.
7. Output ONLY the translated text, nothing more.

**Anime-Specific:**
- Keep Japanese names and honorifics
- Preserve iconic terms and attack names
- Use anime fan-appropriate expressions

{taiwanese_colloquial}
{netflix_rules}
""",
            },
            "movie": {
                "ollama": f"""
You are a professional movie subtitle translator.
Please strictly follow these rules:
1. Only translate the CURRENT text sent to you, NOT any context text.
2. Preserve the exact number of lines in the original text.
3. Keep all formatting, including newlines, in the exact same positions.
4. Maintain the original tone, emotion, and style of dialogue.
5. Translate culturally specific references to be understandable to Taiwan audience.
6. Use natural Taiwan Mandarin Chinese expressions appropriate for film dialogue.
7. Use context (surrounding subtitles) only for understanding, not for inclusion in your output.
8. Your response must contain ONLY the translated text, nothing else.
{name_preservation_rules}
{taiwanese_colloquial}
{netflix_rules}
""",
                "openai": f"""
You are a movie subtitle translator. Your task:
1. ONLY translate the CURRENT text, nothing else. No explanations.
2. Preserve the exact number of lines and formatting of the original.
3. Capture the characters' emotions, slang, and dialogue style.
4. Adapt culturally specific expressions for Taiwan audience.
5. Maintain consistent character voice throughout scenes.
6. Use context for understanding only, NEVER include context text in your translation.
7. Output ONLY the translated text, nothing more.
{name_preservation_rules}
{taiwanese_colloquial}
{netflix_rules}
""",
            },
            "english_drama": {
                "ollama": f"""
âš ï¸ **ABSOLUTE PRIORITY RULE #1 - CONJUNCTION PRESERVATION** âš ï¸
ğŸš¨ **THIS RULE OVERRIDES ALL OTHER CONSIDERATIONS** ğŸš¨

**IF the [CURRENT] sentence ends with a conjunction (when, if, because, although, while, before, after, unless, though, since, until, as, etc.):**
  â†’ YOU **MUST** preserve that conjunction in your translation
  â†’ DO NOT remove it, DO NOT omit it, DO NOT "complete" the sentence
  â†’ KEEP the translation incomplete, matching the original structure

**Examples (MANDATORY):**
  âœ… CORRECT: "...see if Krista orders it when" â†’ "...çœ‹çœ‹å…‹é‡Œæ–¯å¡”æœƒä¸æœƒè¨‚è³¼ç•¶" or "...çœ‹çœ‹ç•¶å…‹é‡Œæ–¯å¡”æœƒä¸æœƒè¨‚è³¼æ™‚"
  âŒ WRONG: "...see if Krista orders it when" â†’ "...çœ‹çœ‹å…‹é‡Œæ–¯å¡”æœƒä¸æœƒè¨‚è³¼" (missing "when")

  âœ… CORRECT: "I will call you if" â†’ "æˆ‘æœƒæ‰“çµ¦ä½ å¦‚æœ" or "å¦‚æœ...æˆ‘æœƒæ‰“çµ¦ä½ "
  âŒ WRONG: "I will call you if" â†’ "æˆ‘æœƒæ‰“çµ¦ä½ " (missing "if")

**WHY THIS MATTERS:** Conjunctions connect to the NEXT subtitle. Removing them breaks semantic continuity and confuses viewers.

---

You are a professional subtitle translator specializing in translating English TV drama/series subtitles into Traditional Chinese (Taiwan).

âš ï¸ **CRITICAL INSTRUCTION** (é•åæ­¤è¦å‰‡å°‡å°è‡´ç¿»è­¯ç„¡æ•ˆ):
- You will receive EXACTLY ONE sentence marked as [CURRENT]
- ONLY translate the [CURRENT] sentence, NOTHING ELSE
- [CONTEXT_BEFORE] and [CONTEXT_AFTER] are for understanding ONLY
- **NEVER combine multiple sentences** into one translation
- **If the current sentence seems incomplete, still translate ONLY that sentence**
- Your output must contain ONLY the translation of [CURRENT], no other text

## Core Translation Principles:

### 1. SRT Format Preservation (CRITICAL)
- **MUST preserve** the complete SRT structure
- **NEVER modify** timecodes under any circumstances
- **MAINTAIN** the original line breaks and pacing structure: if input is 1 line, output MUST be 1 line; if input is 2 lines, output MUST be 2 lines
- **NEVER insert newlines** within a single-line translation - keep it as ONE continuous line
- Only translate the CURRENT text sent to you, NOT any context text

{name_preservation_rules}

### 2. Place Names
- Keep English names for US locations, add Chinese if commonly known
- Use established Taiwanese translations for well-known places
**Examples:**
- "Alabama" â†’ "é˜¿æ‹‰å·´é¦¬"
- "Michigan" â†’ "å¯†è¥¿æ ¹"
- "Detroit" â†’ "åº•ç‰¹å¾‹"
- "House 17" â†’ "17åˆ†å±€" (firehouse numbering)

### 3. Technical Terminology (Example: Firefighting/Medical)
Use standard Taiwanese terminology. Common examples:
- "firefighter" â†’ "æ¶ˆé˜²å“¡"
- "ambulance" â†’ "æ•‘è­·è»Š"
- "Lieutenant" â†’ "å‰¯éšŠé•·"
- "Captain" â†’ "éšŠé•·"
- "shift" â†’ "ç­æ¬¡"

### 4. Tone and Emotion Preservation
- **Maintain original emotional intensity**
- **Don't over-add particles** - keep concise
- Preserve urgency, sarcasm, affection, etc.
**Examples:**
- "Will you marry me?" â†’ "ä½ é¡˜æ„å«çµ¦æˆ‘å—"
- "Help!" â†’ "æ•‘å‘½"
- "Yeah." â†’ "å°"

### 5. Idioms and Slang Translation
Convert to equivalent Taiwanese expressions that convey the same meaning and register.
**Examples:**
- "knuckle sandwich time" â†’ "æˆ‘å°±æ‰“èª°" (direct threat, maintains tone)
- "barking at me" (pain) â†’ "ç—›èµ·ä¾†äº†" (concrete physical sensation)

### 6. Condensation and Simplification
Subtitles must account for reading speed - appropriately condense while retaining core meaning.
- Remove redundant filler words
- Keep semantic core intact
- Maintain clarity over literal accuracy

{taiwanese_colloquial}
{netflix_rules}

## Translation Workflow:
1. Identify key elements (names, places, technical terms, emotional tone, idioms)
2. Keep names in English
3. Use Taiwanese colloquial style
4. Match emotional intensity
5. Your response must contain ONLY the translated text, nothing else
""",
                "openai": f"""
âš ï¸ **ABSOLUTE PRIORITY RULE #1 - CONJUNCTION PRESERVATION** âš ï¸
ğŸš¨ **THIS RULE OVERRIDES ALL OTHER CONSIDERATIONS** ğŸš¨

**IF the [CURRENT] sentence ends with a conjunction (when, if, because, although, while, before, after, unless, though, since, until, as, etc.):**
  â†’ YOU **MUST** preserve that conjunction in your translation
  â†’ DO NOT remove it, DO NOT omit it, DO NOT "complete" the sentence
  â†’ KEEP the translation incomplete, matching the original structure

**Examples (MANDATORY):**
  âœ… CORRECT: "...see if Krista orders it when" â†’ "...çœ‹çœ‹å…‹é‡Œæ–¯å¡”æœƒä¸æœƒè¨‚è³¼ç•¶" or "...çœ‹çœ‹ç•¶å…‹é‡Œæ–¯å¡”æœƒä¸æœƒè¨‚è³¼æ™‚"
  âŒ WRONG: "...see if Krista orders it when" â†’ "...çœ‹çœ‹å…‹é‡Œæ–¯å¡”æœƒä¸æœƒè¨‚è³¼" (missing "when")

  âœ… CORRECT: "I will call you if" â†’ "æˆ‘æœƒæ‰“çµ¦ä½ å¦‚æœ" or "å¦‚æœ...æˆ‘æœƒæ‰“çµ¦ä½ "
  âŒ WRONG: "I will call you if" â†’ "æˆ‘æœƒæ‰“çµ¦ä½ " (missing "if")

**WHY THIS MATTERS:** Conjunctions connect to the NEXT subtitle. Removing them breaks semantic continuity and confuses viewers.

---

You are an expert English-to-Traditional Chinese (Taiwan) subtitle translator for TV dramas and series.

âš ï¸ **CRITICAL INSTRUCTION** (é•åæ­¤è¦å‰‡å°‡å°è‡´ç¿»è­¯ç„¡æ•ˆ):
- You will receive EXACTLY ONE sentence marked as [CURRENT]
- ONLY translate the [CURRENT] sentence, NOTHING ELSE
- [CONTEXT_BEFORE] and [CONTEXT_AFTER] are for understanding ONLY
- **NEVER combine multiple sentences** into one translation
- **If the current sentence seems incomplete, still translate ONLY that sentence**
- Your output must contain ONLY the translation of [CURRENT], no other text

## Critical Rules:
1. ONLY translate the CURRENT text. No warnings, explanations, or quotes.
2. Preserve exact line count: 1 input line = 1 output line, 2 input lines = 2 output lines. NEVER insert newlines in single-line translations.
3. Match original tone and emotion precisely.
4. Use context for understanding only, NEVER include it in translation.
5. Output ONLY the translated text.

{name_preservation_rules}

## Domain-Specific Guidelines:

**Place Names:**
- Keep US location names, add Chinese if well-known
- Examples: "Detroit" â†’ "åº•ç‰¹å¾‹", "Alabama" â†’ "é˜¿æ‹‰å·´é¦¬"

**Technical Terms:**
Use Taiwan standard terminology (adapt to content domain):
- Firefighting: "Lieutenant" â†’ "å‰¯éšŠé•·", "Captain" â†’ "éšŠé•·"
- Medical: "ambulance" â†’ "æ•‘è­·è»Š"
- Generic: adapt based on drama context

**Idioms & Slang:**
Convert to Taiwanese equivalents with same register and impact.
- Maintain comedic/dramatic effect
- Match formality level

**Condensation:**
Balance readability and fidelity:
- Remove non-essential fillers
- Preserve core meaning
- Prioritize natural flow

{taiwanese_colloquial}
{netflix_rules}

Output the translated text directly. No preamble, no explanations.
""",
            },
        }

    def _load_config(self) -> None:
        """è®€å–é…ç½®ä¸¦ç¢ºä¿å¿…è¦çš„è¨­å®šå­˜åœ¨"""
        # å¦‚æœé…ç½®æª”æ¡ˆä¸å­˜åœ¨ï¼Œå°‡ä½¿ç”¨é…ç½®ç®¡ç†å™¨ä¸­çš„é è¨­å€¼
        default_values = {
            "current_content_type": "general",
            "current_style": "standard",
            "current_language_pair": "æ—¥æ–‡â†’ç¹é«”ä¸­æ–‡",
            "custom_prompts": {},
            "version_history": {},
            "last_updated": datetime.now().isoformat(),
        }

        # ç¢ºä¿æ‰€æœ‰é è¨­å€¼éƒ½å­˜åœ¨æ–¼é…ç½®ä¸­
        for key, value in default_values.items():
            if not self.config_manager.get_value(key, None):
                self.config_manager.set_value(key, value, auto_save=False)

        # å„²å­˜é…ç½®
        self.config_manager.save_config()

    def _config_changed(self, config_type: str, config: Dict[str, Any]) -> None:
        """é…ç½®è®Šæ›´æ™‚çš„å›èª¿å‡½æ•¸

        åƒæ•¸:
            config_type: é…ç½®é¡å‹
            config: é…ç½®å…§å®¹
        """
        if config_type != "prompt":
            return

        # æ›´æ–°ç•¶å‰è¨­å®š
        self.current_content_type = config.get("current_content_type", self.current_content_type)
        self.current_style = config.get("current_style", self.current_style)
        self.current_language_pair = config.get("current_language_pair", self.current_language_pair)

        # æ›´æ–°è‡ªè¨‚æç¤ºè©å’Œç‰ˆæœ¬æ­·å²
        self.custom_prompts = config.get("custom_prompts", self.custom_prompts)
        self.version_history = config.get("version_history", self.version_history)

        logger.debug("æç¤ºè©é…ç½®å·²æ›´æ–°")

    def _load_custom_prompts(self) -> None:
        """è¼‰å…¥æ‰€æœ‰è‡ªè¨‚æç¤ºè©"""
        # é¦–å…ˆå¾é…ç½®ä¸­è¼‰å…¥å·²å„²å­˜çš„è‡ªè¨‚æç¤ºè©
        self.custom_prompts = self.config_manager.get_value("custom_prompts", default={}) or {}

        # ç¢ºä¿æ‰€æœ‰å…§å®¹é¡å‹éƒ½å­˜åœ¨
        for content_type in ["general", "adult", "anime", "movie", "english_drama"]:
            if content_type not in self.custom_prompts:
                self.custom_prompts[content_type] = {}

            # æª¢æŸ¥æ˜¯å¦æœ‰å°æ‡‰çš„æ¨¡æ¿æª”æ¡ˆ
            template_file = os.path.join(self.templates_dir, f"{content_type}_template.json")
            if os.path.exists(template_file):
                try:
                    with open(template_file, encoding="utf-8") as f:
                        templates = json.load(f)

                    # åˆä½µæ¨¡æ¿å…§å®¹
                    for llm_type, prompt in templates.items():
                        if llm_type not in self.custom_prompts[content_type]:
                            self.custom_prompts[content_type][llm_type] = prompt

                    logger.debug(f"å·²è¼‰å…¥æ¨¡æ¿: {template_file}")
                except Exception as e:
                    logger.error(f"è¼‰å…¥æ¨¡æ¿æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {format_exception(e)}")

        # æ›´æ–°é…ç½®
        self.config_manager.set_value("custom_prompts", self.custom_prompts)

    def get_prompt(self, llm_type: str = "ollama", content_type: Optional[str] = None, style: Optional[str] = None) -> str:
        """æ ¹æ“š LLM é¡å‹ã€å…§å®¹é¡å‹å’Œé¢¨æ ¼å–å¾—é©åˆçš„ Prompt

        åƒæ•¸:
            llm_type: LLMé¡å‹ (å¦‚ "ollama" æˆ– "openai")
            content_type: å…§å®¹é¡å‹ï¼Œè‹¥ç‚ºNoneå‰‡ä½¿ç”¨ç•¶å‰è¨­å®š
            style: ç¿»è­¯é¢¨æ ¼ï¼Œè‹¥ç‚ºNoneå‰‡ä½¿ç”¨ç•¶å‰è¨­å®š

        å›å‚³:
            æç¤ºè©æ–‡æœ¬
        """
        # ä½¿ç”¨æŒ‡å®šçš„å…§å®¹é¡å‹å’Œé¢¨æ ¼ï¼Œæˆ–ä½¿ç”¨ç•¶å‰è¨­å®š
        content_type = content_type or self.current_content_type
        style = style or self.current_style

        # æª¢æŸ¥æ˜¯å¦æœ‰è‡ªè¨‚æç¤ºè©
        if content_type in self.custom_prompts and llm_type in self.custom_prompts[content_type]:
            prompt = self.custom_prompts[content_type][llm_type]
        else:
            # ä½¿ç”¨é è¨­æç¤ºè©
            if content_type in self.default_prompts and llm_type in self.default_prompts[content_type]:
                prompt = self.default_prompts[content_type][llm_type]
            else:
                # å›é€€åˆ°é€šç”¨æç¤ºè©
                prompt = self.default_prompts["general"].get(llm_type, self.default_prompts["general"]["ollama"])

        # å¥—ç”¨é¢¨æ ¼ä¿®é£¾ç¬¦ï¼ˆå¦‚æœä¸æ˜¯æ¨™æº–é¢¨æ ¼ï¼‰
        if style != "standard":
            prompt = self._apply_style_modifier(prompt, style, llm_type)

        # å¥—ç”¨èªè¨€å°ä¿®é£¾ç¬¦
        prompt = self._apply_language_pair_modifier(prompt, self.current_language_pair)

        return prompt.strip()

    def get_optimized_message(
        self, text: str, context_texts: List[str], llm_type: str, model_name: str
    ) -> List[Dict[str, str]]:
        """æ ¹æ“šä¸åŒLLMå’Œæ¨¡å‹ç”Ÿæˆå„ªåŒ–çš„æç¤ºè¨Šæ¯æ ¼å¼

        åƒæ•¸:
            text: è¦ç¿»è­¯çš„æ–‡å­—
            context_texts: ä¸Šä¸‹æ–‡æ–‡æœ¬åˆ—è¡¨ï¼ˆåŒ…å«å‰æ–‡ã€ç•¶å‰æ–‡æœ¬ã€å¾Œæ–‡ï¼‰
            llm_type: LLMé¡å‹ (å¦‚ "ollama" æˆ– "openai")
            model_name: æ¨¡å‹åç¨±

        å›å‚³:
            é©åˆAPIè«‹æ±‚çš„è¨Šæ¯åˆ—è¡¨
        """
        # ç²å–åŸºæœ¬æç¤ºè©
        prompt = self.get_prompt(llm_type)

        # æ§‹å»ºçµæ§‹åŒ–çš„ä¸Šä¸‹æ–‡è¨Šæ¯
        # context_texts åŒ…å«ç•¶å‰å­—å¹•åŠå…¶å‰å¾Œæ–‡ï¼Œéœ€è¦åˆ†é›¢å‡ºä¾†
        context_before = []
        context_after = []

        # æ‰¾å‡ºç•¶å‰æ–‡æœ¬åœ¨ context_texts ä¸­çš„ä½ç½®
        try:
            current_index = context_texts.index(text)
            context_before = context_texts[:current_index]
            context_after = context_texts[current_index + 1 :]
        except ValueError:
            # å¦‚æœæ‰¾ä¸åˆ°ç•¶å‰æ–‡æœ¬ï¼ˆæ¥µå°‘æ•¸æƒ…æ³ï¼‰ï¼Œä½¿ç”¨åŸæœ‰æ–¹å¼
            logger.warning("ç„¡æ³•åœ¨ä¸Šä¸‹æ–‡ä¸­æ‰¾åˆ°ç•¶å‰æ–‡æœ¬ï¼Œä½¿ç”¨èˆŠæ ¼å¼")
            context_before = context_texts
            context_after = []

        # æª¢æ¸¬å¥å­æ˜¯å¦ä»¥é€£æ¥è©çµå°¾
        conjunctions = [
            "when",
            "if",
            "because",
            "although",
            "while",
            "before",
            "after",
            "unless",
            "though",
            "since",
            "until",
            "as",
            "where",
            "whereas",
        ]
        text_lower = text.strip().lower()
        ends_with_conjunction = any(text_lower.endswith(f" {conj}") for conj in conjunctions)

        # æ§‹å»ºæ–°æ ¼å¼çš„ user message
        user_content_parts = []

        # å¦‚æœä»¥é€£æ¥è©çµå°¾ï¼Œæ·»åŠ è¶…å¼·è­¦å‘Š
        if ends_with_conjunction:
            detected_conj = next(conj for conj in conjunctions if text_lower.endswith(f" {conj}"))
            user_content_parts.extend(
                [
                    "ğŸš¨ **MANDATORY WARNING** ğŸš¨",
                    f"The [CURRENT] sentence ends with the conjunction '{detected_conj.upper()}'.",
                    f"YOU **MUST** PRESERVE '{detected_conj.upper()}' in your translation.",
                    'DO NOT remove it. DO NOT omit it. DO NOT "complete" the sentence.',
                    "Keep the translation incomplete, matching the original structure.",
                    "",
                    "---",
                    "",
                ]
            )

        user_content_parts.extend(["[CURRENT] (è«‹åªç¿»è­¯é€™ä¸€å¥):", text, ""])

        if context_before:
            user_content_parts.append("[CONTEXT_BEFORE] (å‰æ–‡åƒè€ƒï¼Œä¸è¦ç¿»è­¯):")
            for ctx in context_before:
                user_content_parts.append(f"- {ctx}")
            user_content_parts.append("")

        if context_after:
            user_content_parts.append("[CONTEXT_AFTER] (å¾Œæ–‡åƒè€ƒï¼Œä¸è¦ç¿»è­¯):")
            for ctx in context_after:
                user_content_parts.append(f"- {ctx}")

        user_message = "\n".join(user_content_parts)

        # ç‚ºä¸åŒçš„LLMé¡å‹å‰µå»ºä¸åŒæ ¼å¼çš„è¨Šæ¯
        if llm_type == "openai" or llm_type == "anthropic":
            # OpenAI/Anthropicçš„è¨Šæ¯æ ¼å¼
            messages = [{"role": "system", "content": prompt}, {"role": "user", "content": user_message}]
        else:
            # Ollamaç­‰å…¶ä»–LLMçš„è¨Šæ¯æ ¼å¼
            messages = [{"role": "system", "content": prompt}, {"role": "user", "content": user_message}]

        return messages

    def _apply_style_modifier(self, prompt: str, style: str, llm_type: str) -> str:
        """æ ¹æ“šç¿»è­¯é¢¨æ ¼ä¿®æ”¹æç¤ºè©

        åƒæ•¸:
            prompt: åŸå§‹æç¤ºè©
            style: ç¿»è­¯é¢¨æ ¼
            llm_type: LLMé¡å‹

        å›å‚³:
            ä¿®æ”¹å¾Œçš„æç¤ºè©
        """
        style_modifiers = {
            "literal": {
                "ollama": "Focus on providing a more literal translation that is closer to the original text meaning. Prioritize accuracy to source text over natural flow in the target language. Remember to ONLY translate the CURRENT text, not context.",
                "openai": "Translate literally. Prioritize source accuracy over target fluency. Only translate the current text, never context.",
            },
            "localized": {
                "ollama": "Focus on adapting the content to the target culture. Use Taiwan-specific expressions, cultural references, and idioms where appropriate to make the translation feel natural to local readers. Remember to ONLY translate the CURRENT text, not context.",
                "openai": "Translate with cultural adaptation. Use Taiwan expressions and references. Only translate the current text, never context.",
            },
            "specialized": {
                "ollama": "Focus on accurate translation of terminology relevant to the content domain. Prioritize precision in specialized terms and concepts. Remember to ONLY translate the CURRENT text, not context.",
                "openai": "Translate with domain precision. Prioritize accurate terminology. Only translate the current text, never context.",
            },
        }

        if style in style_modifiers and llm_type in style_modifiers[style]:
            modifier = style_modifiers[style][llm_type]
            # åœ¨æç¤ºè©çµå°¾æ·»åŠ é¢¨æ ¼ä¿®é£¾ç¬¦
            return f"{prompt}\n\nAdditional instruction: {modifier}"

        return prompt

    def _apply_language_pair_modifier(self, prompt: str, language_pair: str) -> str:
        """æ ¹æ“šèªè¨€å°ä¿®æ”¹æç¤ºè©

        åƒæ•¸:
            prompt: åŸå§‹æç¤ºè©
            language_pair: èªè¨€å° (å¦‚ "æ—¥æ–‡â†’ç¹é«”ä¸­æ–‡")

        å›å‚³:
            ä¿®æ”¹å¾Œçš„æç¤ºè©
        """
        # å¦‚æœæ˜¯é è¨­çš„æ—¥æ–‡â†’ç¹é«”ä¸­æ–‡ï¼Œä¸éœ€è¦ä¿®æ”¹
        if language_pair == "æ—¥æ–‡â†’ç¹é«”ä¸­æ–‡":
            return prompt

        # å–å¾—ä¾†æºèªè¨€å’Œç›®æ¨™èªè¨€
        if language_pair in self.language_pairs:
            source = self.language_pairs[language_pair]["source"]
            target = self.language_pairs[language_pair]["target"]

            # åŸºæ–¼æ­£å‰‡è¡¨é”å¼æ›´æ–°æç¤ºè©ä¸­çš„èªè¨€å¼•ç”¨
            # å°‹æ‰¾ä¸¦æ›¿æ›ç¹é«”ä¸­æ–‡/Taiwan Mandarin ç­‰ç›¸é—œæç¤º
            prompt = re.sub(r"(Taiwan Mandarin|ç¹é«”ä¸­æ–‡|Traditional Chinese)", target, prompt)

            # æ·»åŠ æ˜ç¢ºçš„èªè¨€å°èªªæ˜
            language_instruction = (
                f"\nTranslate from {source} to {target}. Remember to ONLY translate the CURRENT text, not context."
            )
            return f"{prompt}{language_instruction}"

        return prompt

    def set_prompt(self, new_prompt: str, llm_type: str = "ollama", content_type: Optional[str] = None) -> bool:
        """è¨­ç½®ç‰¹å®š LLM å’Œå…§å®¹é¡å‹çš„æç¤ºè©

        åƒæ•¸:
            new_prompt: æ–°çš„æç¤ºè©
            llm_type: LLMé¡å‹ (å¦‚ "ollama" æˆ– "openai")
            content_type: å…§å®¹é¡å‹ï¼Œè‹¥ç‚ºNoneå‰‡ä½¿ç”¨ç•¶å‰è¨­å®š

        å›å‚³:
            æ˜¯å¦è¨­ç½®æˆåŠŸ
        """
        content_type = content_type or self.current_content_type

        # ç¢ºä¿è‡ªè¨‚æç¤ºè©å­—å…¸ä¸­æœ‰å°æ‡‰çš„å…§å®¹é¡å‹
        if content_type not in self.custom_prompts:
            self.custom_prompts[content_type] = {}

        # å„²å­˜èˆŠçš„æç¤ºè©ç‰ˆæœ¬
        old_prompt = self.custom_prompts.get(content_type, {}).get(llm_type)
        if old_prompt:
            self._add_to_version_history(content_type, llm_type, old_prompt)

        # æ›´æ–°æç¤ºè©
        self.custom_prompts[content_type][llm_type] = new_prompt.strip()

        # æ›´æ–°é…ç½®
        self.config_manager.set_value("custom_prompts", self.custom_prompts)

        # å„²å­˜è‡³æ¨¡æ¿æª”æ¡ˆ
        self._save_prompt_template(content_type)

        logger.info(f"å·²è¨­ç½® '{content_type}' é¡å‹çš„ '{llm_type}' æç¤ºè©")
        return True

    def _add_to_version_history(self, content_type: str, llm_type: str, prompt: str) -> None:
        """å°‡æç¤ºè©æ·»åŠ åˆ°ç‰ˆæœ¬æ­·å²

        åƒæ•¸:
            content_type: å…§å®¹é¡å‹
            llm_type: LLMé¡å‹
            prompt: æç¤ºè©
        """
        if content_type not in self.version_history:
            self.version_history[content_type] = {}

        if llm_type not in self.version_history[content_type]:
            self.version_history[content_type][llm_type] = []

        # æ·»åŠ ç‰ˆæœ¬è¨˜éŒ„
        version_entry = {
            "prompt": prompt,
            "timestamp": datetime.now().isoformat(),
            "version": len(self.version_history[content_type][llm_type]) + 1,
        }

        # ç¶­è­·æœ€å¤š 10 å€‹ç‰ˆæœ¬
        history = self.version_history[content_type][llm_type]
        history.append(version_entry)
        if len(history) > 10:
            history = history[-10:]  # åªä¿ç•™æœ€æ–°çš„ 10 å€‹ç‰ˆæœ¬
            self.version_history[content_type][llm_type] = history

        # æ›´æ–°é…ç½®
        self.config_manager.set_value("version_history", self.version_history)

    def _save_prompt_template(self, content_type: str) -> bool:
        """å„²å­˜æç¤ºè©æ¨¡æ¿è‡³æª”æ¡ˆ

        åƒæ•¸:
            content_type: å…§å®¹é¡å‹

        å›å‚³:
            æ˜¯å¦å„²å­˜æˆåŠŸ
        """
        template_file = os.path.join(self.templates_dir, f"{content_type}_template.json")
        try:
            # ç¢ºä¿ç›®éŒ„å­˜åœ¨
            os.makedirs(self.templates_dir, exist_ok=True)

            with open(template_file, "w", encoding="utf-8") as f:
                json.dump(self.custom_prompts[content_type], f, ensure_ascii=False, indent=4)
            logger.debug(f"å·²å„²å­˜æ¨¡æ¿è‡³: {template_file}")
            return True
        except Exception as e:
            logger.error(f"å„²å­˜æ¨¡æ¿æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {format_exception(e)}")
            return False

    def get_version_history(self, content_type: Optional[str] = None, llm_type: Optional[str] = None) -> List[Dict[str, Any]]:
        """å–å¾—æç¤ºè©çš„ç‰ˆæœ¬æ­·å²

        åƒæ•¸:
            content_type: å…§å®¹é¡å‹ï¼Œè‹¥ç‚ºNoneå‰‡ä½¿ç”¨ç•¶å‰è¨­å®š
            llm_type: LLMé¡å‹ï¼Œè‹¥ç‚ºNoneå‰‡è¿”å›æ‰€æœ‰LLMé¡å‹çš„æ­·å²

        å›å‚³:
            ç‰ˆæœ¬æ­·å²åˆ—è¡¨
        """
        content_type = content_type or self.current_content_type

        if content_type not in self.version_history:
            return []

        if llm_type:
            return list(self.version_history[content_type].get(llm_type, []))

        # åˆä½µæ‰€æœ‰ LLM é¡å‹çš„æ­·å²è¨˜éŒ„
        all_history = []
        for llm, history in self.version_history[content_type].items():
            for entry in history:
                entry_with_llm = entry.copy()
                entry_with_llm["llm_type"] = llm
                all_history.append(entry_with_llm)

        # æŒ‰æ™‚é–“æ’åº
        all_history.sort(key=lambda x: x["timestamp"], reverse=True)
        return all_history

    def restore_version(self, content_type: str, llm_type: str, version_index: int) -> bool:
        """æ¢å¾©åˆ°ç‰¹å®šç‰ˆæœ¬çš„æç¤ºè©

        åƒæ•¸:
            content_type: å…§å®¹é¡å‹
            llm_type: LLMé¡å‹
            version_index: ç‰ˆæœ¬ç´¢å¼•

        å›å‚³:
            æ˜¯å¦æ¢å¾©æˆåŠŸ
        """
        if (
            content_type in self.version_history
            and llm_type in self.version_history[content_type]
            and 0 <= version_index < len(self.version_history[content_type][llm_type])
        ):
            # å–å¾—è¦æ¢å¾©çš„ç‰ˆæœ¬
            version = self.version_history[content_type][llm_type][version_index]

            # è¨­ç½®æç¤ºè©
            self.set_prompt(version["prompt"], llm_type, content_type)

            logger.info(f"å·²æ¢å¾© '{content_type}' é¡å‹çš„ '{llm_type}' æç¤ºè©åˆ°ç‰ˆæœ¬ {version['version']}")
            return True

        logger.warning("ç„¡æ³•æ¢å¾©ç‰ˆæœ¬ï¼Œæ‰¾ä¸åˆ°å°æ‡‰çš„ç‰ˆæœ¬è¨˜éŒ„")
        return False

    def reset_to_default(self, llm_type: Optional[str] = None, content_type: Optional[str] = None) -> bool:
        """é‡ç½®ç‚ºé è¨­æç¤ºè©

        åƒæ•¸:
            llm_type: LLMé¡å‹ï¼Œè‹¥ç‚ºNoneå‰‡é‡ç½®æ‰€æœ‰LLMé¡å‹
            content_type: å…§å®¹é¡å‹ï¼Œè‹¥ç‚ºNoneå‰‡ä½¿ç”¨ç•¶å‰è¨­å®š

        å›å‚³:
            æ˜¯å¦é‡ç½®æˆåŠŸ
        """
        content_type = content_type or self.current_content_type

        if llm_type:
            # é‡ç½®ç‰¹å®š LLM é¡å‹çš„æç¤ºè©
            if content_type in self.default_prompts and llm_type in self.default_prompts[content_type]:
                self.set_prompt(self.default_prompts[content_type][llm_type], llm_type, content_type)
                logger.info(f"å·²é‡ç½® '{content_type}' é¡å‹çš„ '{llm_type}' æç¤ºè©ç‚ºé è¨­å€¼")
                return True
        else:
            # é‡ç½®æ‰€æœ‰ LLM é¡å‹çš„æç¤ºè©
            success = True
            for llm in ["ollama", "openai"]:
                if content_type in self.default_prompts and llm in self.default_prompts[content_type]:
                    result = self.set_prompt(self.default_prompts[content_type][llm], llm, content_type)
                    success = success and result
            logger.info(f"å·²é‡ç½® '{content_type}' é¡å‹çš„æ‰€æœ‰æç¤ºè©ç‚ºé è¨­å€¼")
            return success

        return False

    def set_content_type(self, content_type: str) -> bool:
        """è¨­ç½®ç•¶å‰ä½¿ç”¨çš„å…§å®¹é¡å‹

        åƒæ•¸:
            content_type: å…§å®¹é¡å‹

        å›å‚³:
            æ˜¯å¦è¨­ç½®æˆåŠŸ
        """
        if content_type in ["general", "adult", "anime", "movie", "english_drama"]:
            self.current_content_type = content_type
            self.config_manager.set_value("current_content_type", content_type)
            logger.info(f"å·²è¨­ç½®ç•¶å‰å…§å®¹é¡å‹ç‚º: {content_type}")
            return True
        return False

    def set_translation_style(self, style: str) -> bool:
        """è¨­ç½®ç•¶å‰ä½¿ç”¨çš„ç¿»è­¯é¢¨æ ¼

        åƒæ•¸:
            style: ç¿»è­¯é¢¨æ ¼

        å›å‚³:
            æ˜¯å¦è¨­ç½®æˆåŠŸ
        """
        if style in self.translation_styles:
            self.current_style = style
            self.config_manager.set_value("current_style", style)
            logger.info(f"å·²è¨­ç½®ç•¶å‰ç¿»è­¯é¢¨æ ¼ç‚º: {style}")
            return True
        return False

    def set_language_pair(self, language_pair: str) -> bool:
        """è¨­ç½®ç•¶å‰ä½¿ç”¨çš„èªè¨€å°

        åƒæ•¸:
            language_pair: èªè¨€å°

        å›å‚³:
            æ˜¯å¦è¨­ç½®æˆåŠŸ
        """
        if language_pair in self.language_pairs:
            self.current_language_pair = language_pair
            self.config_manager.set_value("current_language_pair", language_pair)
            logger.info(f"å·²è¨­ç½®ç•¶å‰èªè¨€å°ç‚º: {language_pair}")
            return True
        return False

    def get_available_content_types(self) -> List[str]:
        """å–å¾—å¯ç”¨çš„å…§å®¹é¡å‹

        å›å‚³:
            å…§å®¹é¡å‹åˆ—è¡¨
        """
        return ["general", "adult", "anime", "movie", "english_drama"]

    def get_available_styles(self) -> Dict[str, str]:
        """å–å¾—å¯ç”¨çš„ç¿»è­¯é¢¨æ ¼

        å›å‚³:
            ç¿»è­¯é¢¨æ ¼å­—å…¸ {é¢¨æ ¼ä»£ç¢¼: é¢¨æ ¼æè¿°}
        """
        return self.translation_styles

    def get_available_language_pairs(self) -> List[str]:
        """å–å¾—å¯ç”¨çš„èªè¨€å°

        å›å‚³:
            èªè¨€å°åˆ—è¡¨
        """
        return list(self.language_pairs.keys())

    def export_prompt(self, content_type: Optional[str] = None, llm_type: Optional[str] = None, file_path: Optional[str] = None) -> Optional[str]:
        """åŒ¯å‡ºæç¤ºè©è‡³æª”æ¡ˆ

                åƒæ•¸:
                    content_type: å…§å®¹é¡å‹ï¼Œè‹¥ç‚ºNoneå‰‡ä½¿ç”¨ç•¶å‰è¨­å®š
                    llm_type: LLMé¡å‹ï¼Œè‹¥ç‚ºNoneå‰‡åŒ¯å‡ºæ‰€æœ‰LLMé¡å‹çš„æç¤ºè©
                    file_path: è¼¸å‡ºæª”æ¡ˆè·¯å¾‘ï¼Œè‹¥ç‚ºNoneå‰‡è‡ªå‹•ç”Ÿæˆ

                å›å‚³:
        åŒ¯å‡ºæª”æ¡ˆè·¯å¾‘ï¼Œè‹¥å¤±æ•—å‰‡å›å‚³None
        """
        content_type = content_type or self.current_content_type

        # è¦åŒ¯å‡ºçš„è³‡æ–™
        export_data = {
            "metadata": {"exported_at": datetime.now().isoformat(), "content_type": content_type, "version": "1.0"},
            "prompts": {},
        }

        if llm_type:
            # åŒ¯å‡ºç‰¹å®š LLM çš„æç¤ºè©
            if content_type in self.custom_prompts and llm_type in self.custom_prompts[content_type]:
                export_data["prompts"][llm_type] = self.custom_prompts[content_type][llm_type]
            else:
                # ä½¿ç”¨é è¨­æç¤ºè©
                export_data["prompts"][llm_type] = self.default_prompts[content_type].get(llm_type, "")
        else:
            # åŒ¯å‡ºæ‰€æœ‰ LLM çš„æç¤ºè©
            for llm in ["ollama", "openai"]:
                if content_type in self.custom_prompts and llm in self.custom_prompts[content_type]:
                    export_data["prompts"][llm] = self.custom_prompts[content_type][llm]
                else:
                    # ä½¿ç”¨é è¨­æç¤ºè©
                    export_data["prompts"][llm] = self.default_prompts[content_type].get(llm, "")

        # ç”Ÿæˆè¼¸å‡ºæª”æ¡ˆè·¯å¾‘
        if not file_path:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            file_name = f"prompt_export_{content_type}_{timestamp}.json"
            file_path = os.path.join(self.templates_dir, file_name)

        try:
            # ç¢ºä¿ç›®éŒ„å­˜åœ¨
            os.makedirs(os.path.dirname(file_path), exist_ok=True)

            with open(file_path, "w", encoding="utf-8") as f:
                json.dump(export_data, f, ensure_ascii=False, indent=4)
            logger.info(f"å·²åŒ¯å‡ºæç¤ºè©è‡³: {file_path}")
            return file_path
        except Exception as e:
            logger.error(f"åŒ¯å‡ºæç¤ºè©æ™‚ç™¼ç”ŸéŒ¯èª¤: {format_exception(e)}")
            return None

    def import_prompt(self, input_path: str) -> bool:
        """å¾æª”æ¡ˆåŒ¯å…¥æç¤ºè©

        åƒæ•¸:
            input_path: è¼¸å…¥æª”æ¡ˆè·¯å¾‘

        å›å‚³:
            æ˜¯å¦åŒ¯å…¥æˆåŠŸ
        """
        try:
            if not os.path.exists(input_path):
                logger.error(f"åŒ¯å…¥æª”æ¡ˆä¸å­˜åœ¨: {input_path}")
                return False

            with open(input_path, encoding="utf-8") as f:
                import_data = json.load(f)

            # é©—è­‰åŒ¯å…¥è³‡æ–™æ ¼å¼
            if not all(k in import_data for k in ["metadata", "prompts"]):
                logger.warning(f"ç„¡æ•ˆçš„æç¤ºè©åŒ¯å…¥æ ¼å¼: {input_path}")
                return False

            content_type = import_data["metadata"].get("content_type", "general")

            # åŒ¯å…¥æç¤ºè©
            for llm_type, prompt in import_data["prompts"].items():
                if llm_type not in ["ollama", "openai"]:
                    logger.warning(f"è·³éä¸æ”¯æ´çš„LLMé¡å‹: {llm_type}")
                    continue
                self.set_prompt(prompt, llm_type, content_type)

            logger.info(f"å·²å¾ {input_path} åŒ¯å…¥ '{content_type}' é¡å‹çš„æç¤ºè©")
            return True
        except Exception as e:
            logger.error(f"åŒ¯å…¥æç¤ºè©æ™‚ç™¼ç”ŸéŒ¯èª¤: {format_exception(e)}")
            return False

    def analyze_prompt(self, prompt: str) -> Dict[str, Any]:
        """åˆ†ææç¤ºè©æ–‡æœ¬çš„å“è³ªå¾—åˆ†

        åƒæ•¸:
            prompt: è¦åˆ†æçš„æç¤ºè©æ–‡æœ¬

        å›å‚³:
            åˆ†æçµæœå­—å…¸
        """
        analysis = {
            "length": len(prompt),
            "word_count": len(prompt.split()),
            "contains_rules": False,
            "contains_examples": False,
            "contains_constraints": False,
            "clarity": 0,
            "specificity": 0,
            "completeness": 0,
            "formatting_score": 0,
            "quality_score": 0,
        }
        # æª¢æ¸¬æ˜¯å¦åŒ…å«è¦å‰‡
        if re.search(r"(rule|guidelines|follow these|instructions|è«‹éµå®ˆ)", prompt, re.IGNORECASE):
            analysis["contains_rules"] = True
            analysis["clarity"] += 1

        # æª¢æ¸¬æ˜¯å¦åŒ…å«ä¾‹å­
        if re.search(r"(example|for instance|such as|èˆ‰ä¾‹|ä¾‹å¦‚)", prompt, re.IGNORECASE):
            analysis["contains_examples"] = True
            analysis["specificity"] += 1

        # æª¢æ¸¬æ˜¯å¦åŒ…å«ç´„æŸæ¢ä»¶
        if re.search(r"(only|must|should|do not|avoid|ç¦æ­¢|ä¸è¦|å¿…é ˆ)", prompt, re.IGNORECASE):
            analysis["contains_constraints"] = True
            analysis["completeness"] += 1

        # æª¢æ¸¬æ ¼å¼åŒ–ç¨‹åº¦
        if prompt.count("\n") > 3:
            analysis["formatting_score"] += 1

        if re.search(r"(\d+\.|\*|-|\d+\))", prompt):
            analysis["formatting_score"] += 1

        # è¨ˆç®—ç¸½é«”å¾—åˆ†
        analysis["clarity"] += min(3, prompt.count(".") // 3)
        analysis["specificity"] += min(
            3, len(re.findall(r"\b(translate|ç¿»è­¯|maintain|ä¿æŒ|preserve|keep|ç¢ºä¿)\b", prompt, re.IGNORECASE))
        )
        analysis["completeness"] += min(
            3, len(re.findall(r"\b(tone|style|context|èªæ°£|é¢¨æ ¼|ä¸Šä¸‹æ–‡)\b", prompt, re.IGNORECASE))
        )

        # èª¿æ•´åˆ†æ•¸ç¯„åœ (0-5)
        for key in ["clarity", "specificity", "completeness", "formatting_score"]:
            analysis[key] = min(5, analysis[key])

        # è¨ˆç®—ç¸½é«”å“è³ªå¾—åˆ† (0-100)
        analysis["quality_score"] = (
            (analysis["clarity"] * 20)
            + (analysis["specificity"] * 20)
            + (analysis["completeness"] * 20)
            + (analysis["formatting_score"] * 10)
            + (30 if analysis["contains_rules"] and analysis["contains_constraints"] else 0)
        ) // 5

        return analysis
